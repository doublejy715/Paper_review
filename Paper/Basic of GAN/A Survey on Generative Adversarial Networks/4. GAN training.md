# 4. GAN training
## 4.1. Problem with training GAN
GAN 은 좋은 생성기를 만들어 낸다. 그러나 GAN이 안정한 학습을 하기 위해서는 중요한 요소들이 있다.

### 4.1.1 Nash equilibrium
GAN은 deep neural network를 2개 학습한다. 서로 경쟁하는 Nash-equilibrium의 탐색을 위해 적대적으로 네트워크가 학습된다. 

G와 D이 cost function을 통해서 독립적으로 업데이트 된다면 Nash-equilibrium을 얻기가 힘들어지고 GAN의 학습은 불안정하게 된다. GAN을 안정하게 학습하기 위해서는 Nash-equilibrium은 매우 중요하다.

> 이해를 위해 간단한 예시를 보인다.
>두 명의 게임 플레이어 A,B가 있다고 가정한다. 이 A,B는 x와 y를 관리한다. A는 (xy) 값을 최소화 하기 위해서 노력하며 B는 최대화 하기 위해서 노력한다.
>$$
>V(x,y) = xy
>$$
> 위의 식에서 $\delta xV(x,y)=0$ 와 $\delta yV(x,y)=0$ 이므로, x=y=0이 saddle point가 된다.(Nash-equilibrium)

gradient descent optimizer를 가지고 어떻게 Nash-equilibrium을 찾아내었는지 살펴본다. 

value function V에 gradient descent를 이용하여 x와 y의 parameter를 업데이트 한다.
$$
\Delta x = \alpha{\delta(xy) \over \delta(x)}
$$
$$
\Delta y = -\alpha{\delta(xy) \over \delta(y)} 
$$

$\alpha$은 learning rate이다. x, y, xy는 여러번의 학습에도 불구하고 밑의 사진과 같이 수렴하지 않는 모습을 보인다.
[Figure 10]

### 4.1.2 Internal covariate shift(ICS)
- Covariate Shift : 이전 layer의 파라미터 변화로 인해 현재 layer의 입력의 분포가 바뀌는 현상

딥러닝에는 대부분 GPU가 사용되고 있으며. GPU를 효율적으로 사용할 수 있도록 보통 32~256 sizedml mini-batch SGD(stochastic gradient descent) 방법을 많이 사용한다.

SGD 방식으로 효과를 보기 위해서는 hyper-parameter의 설정에 신경을 많이 써줘야 하며, 특히 초기값과 학습 진도율은 매우 중요한 요소가 된다.

그러나 hyper-parameter 외에도 학습에 영향을 미치는 요소가 있다. 네트워크 입력의 분포가 달라지게 되면 중간 레이어(hidden layers)는 새로운 분포를 학습하게 된다. 이러한 학습 parameter들은 모델의 학습을 느리게 한다.

[Covariate shift 관련 설명](https://blog.naver.com/PostView.nhn?blogId=laonple&logNo=220808903260)

### 4.1.3 Mode collapse
GAN 학습에 있어서 가장 많이 언급되는 문제이다. generator가 항상 같은 결과를 내놓는 현상을 의미한다. 

Mode collapse는 데이터의 다양성 부족으로 인해 발생하는 일반적인 generator 문제이다. Mode collapse는 크게 partial, complete type으로 2가지 형식으로 나타난다.

- Partial type : 적은 다양성을 보이는 문제
- Completer type : 가장 안좋은 경우이며, 한가지 종류의 이미지만 계속 생성하는 문제

### 4.1.4 Vanishing gradient
GAN은 vanishing gradient(VG) 문제로 인해서 학습하기 어렵다. 이것 또한 generator에서 발생하는 문제로 VG로 인해서 저퀄리티의 이미지가 생성된다. 

VG는 generator의 gradients들이 깊은 레이어에서 작게 나오면 처음 layer로 갈수록 graidents가 사라지게 되어 학습이 되지 않는 문제를 의미한다.

잘 학습된 Discriminator는 generator에서 생성된 sample를 보고 단박에 거짓임을 판별한다. 
 


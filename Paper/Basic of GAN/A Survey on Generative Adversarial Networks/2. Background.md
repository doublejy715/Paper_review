# 2. Background
Generative models(GM)은 computer vision에 있어서 많은 발전을 가져다 주었다. 
Generative model은 training data ~ ![image](https://user-images.githubusercontent.com/54474501/145373066-adc5a172-a7a9-4060-aa28-ff26f017a07b.png)를 가지고 unsupervised learning을 실시한다. 학습된 model은 training data와 비슷한 생성 분포를 가지게 되고, 새로운 sample data를 생성할 수 있게 된다.

왜 generative model 인가?
- 실제적인 sample을 생성 가능하고 
- GM 학습은 latent representation의 간섭을 가능하게 하여 feature 생성기로 사용 가능하다.
- unsupervised learning의 density estimation problem문제 해결
- 사람의 감독&간섭 없이 훈련을 통해 새로운 데이터를 생성함으로서 위 문제를 해결하였음.

## 2.1 Autoencoder(AE)
- Autoencoder는 high dimensionality data를 함축된 small dimensionality data로 줄여주는 generative model이다.
- AE는 encoder와 decoder 네트워크로 분류된다.
- encoder : input data를 받으면 layers를 거쳐 small dimension로 함축된다.
- decoder :  bottleneck을 가지고 input data의 reconstruction을 시도한다.
- AE는 input과 output간 픽셀값 간의 차이를 통해 loss를 계산한다.

$$
L_{AE} = {1\over n} \displaystyle\sum_{i=1}^{n}[x-f_{(\theta)}(g_{(\phi)}(x))]^{2}
$$

[Figure 2]

## 2.2 Variational Autoencoder(VAE)
- Variational Autoencoder(VAE)는 likelihood 기반 generative model로 널리 알려져 있다.
- VAE는 확률분포적인 encoder / decoder network를 가진다.
- encoder : input data를 encoder를 통하여 input data의 확률 분포를 찾아낸다.
- decoder : encoder에서 나온 Input의 평균과 분산 값으로 확률 분포를 생성한다. 확률 분포를 통해서 z latent vector를 만든다. 이 z를 가지고 다시 input data를 생성한다.

$$
L_{VAE} = \Epsilon_{q_{\phi}(z|x)}[\log p_{\theta}(x|z)] - D_{KL}[(q_{\phi}(z|x)||p_{\theta}(z))]
$$

[Figure 3]

> AE vs VAE
> - AE : input data를 잠재 공간 z에 대응시켜 벡터 값을 저장한다.
> - VAE : 확률 분포를 저장하여 (평균, 분산) 파라미터를 생성한다.(확률 분포를 생성)
> [AE vs VAE 차이의 이해](https://medium.com/@seyong.dev/vae-variational-auto-encoder-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-60032f19b9e3)
> [AE vs VAE 차이의 이해 2](https://perpetual.tistory.com/85)


## 2.3 Generative Adversarial Networks(GAN)
- GAN은 unsupervised machine learning를 통해 학습되는 robust network 이다.
- 주로 2개 네트워크 generator network(G), discriminator network(D)로 이루어져 있다.
- G는 D를 속이기 위한 가짜 데이터를 생성하고, D는 G가 생성한 데이터가 가짜임을 판별한다.
- 학습을 통하여 G는 진짜같은 가짜 데이터를 목표하고 D는 높은 판별 능력을 목표한다.

$$
L_{GAN} = V(D,G) = \Epsilon_{x\sim p_{data}(x)}[log(D(x))]+\Epsilon_{z\sim p_{z}}(z)[log(1-D(G(z)))]
$$

- log(D(x)) 는 D network의 loss function
- log(1-D(G(z))) 는 G network의 loss function

[Figure 4]

## 2.4 Glow

## 2.5 Vector Quantized Variational AutoEncoder-2(VQ-VAE-2)
- VQ-VAE-2는 Vector Quantized VAE(VQ-VAE)의 향상된 버전이다.(VQ-VAE는 큰 사이즈의 이미지를 생성한다.)
- 단순한 feed-forward encoder와 decoder를 사용하였음
- 1000x1000 사이즈 이미지를 빠르고 다양하게 생성 가능하다.

### 학습 과정
- stage 1 : input image를 encoder에 입력한다. encoder에서 local information과 global detail이 결과로 나온다.
- Stage 2 : Autoregressive model에 Stage 1에서 나온 2값을 넣어준다. 간단한 feed-forward decoder를 통해 input image 사이즈와 같은 크기로 재 생성 한다.

[VQ-VAE-2 paper review](https://greeksharifa.github.io/discrete%20representation/2021/11/26/VQVAE2/)

## 2.6 GAN variants
### 2.6.1 Conditional GAN(CGAN)
- GAN의 conditional version이다.
- 이러한 유형의 network는 class label과 같은 추가 정보를 제공한다.
- CGAN의 Generator는 c(class label or = text or image)를 추가 정보로 받아 latent vector z를 만든다.($G(z|c)$)
- CGAN의 discriminator는 G로 인해 생성된 데이터를 판별한다.($D(G(z|c))$)

$$
L_{CGAN} = \Epsilon_{x \sim p_{data}(x)}[log(D(x|c))] + \Epsilon_{z \sim p_{z}(z)}[log(1-D(G(z|c)))]
$$

[Figure 5]

Q : real data x와 condition c는 항상 pair가 되어야 하나?

### 2.6.2 Deep Convolutional GAN(DCGAN)
- 새로운 convolutional neural networks(CNN) 유형이다.
- DCGAN은 첫 practied de-convolutional neural networks(de-CNN) 구조다.
- generator는 CNN 처럼 구성되었고, discriminator는 de-CNN으로 구성된 네트워크다.
- G,D 둘다 Batch Normalization(BN)을 사용하였음.
- ReLU 와 Leaky-ReLu를 G, D network에 사용함

[DCGAN paper review](https://ysbsb.github.io/gan/2020/12/05/DCGAN.html)

### 2.6.3 Laplacian GAN(LapGAN)
- CNN을 GAN에 적용하려는 시도 중 하나
- 유의미한 성능향상이 없었음

### 2.6.4 Information Maximizing Generative Adversarial Networks (InfoGAN)
- DCGAN에선 Z representation에 대한 벡터 값을 일일이 수동으로 변화시키면서 결과를 얻었음.
- InfoGAN은 GAN framework로 이루어져 있고, discrete하고 continuous한 latent factor들을 disentangles 하게 학습한다.

$$
L_{InfoGAN} = V(D,G) - \lambda I(c;G(z,c))  
$$

> $\lambda$ : hyper-parameter  
> z : un-interpretable noise  
> c : encodes the salient latent codes  

#### Semi-supervised InfoGAN(SS-InfoGAN)
- InfoGAN과 비슷하게, Semi-supervised InfoGAN(SS-InfoGAN)은 supervised와 unsupervised learning 두 장점을 모두 가진다.
- un-supervised latent code과 synthesized data 간에 여러 정보를 제공할 수 있다. 
- unlabeled dataset을 가지고 SS-InfoGAN

### 2.6.5 Energy-Based Generative Adversarial Networks (EBGAN)
- GAN architecture의 변형된 것으로 AE와 GAN이 결합되어 있는 모습을 가진다.
- GAN training시 energy-based model을 사용하였음
- EBGAN의 D는 Auto-Encoder의 구조를 사용한다.
- EBGAN은 G와 D에 각각 다른 loss를 이용한다.

$$
L_{D}(x,z) = D(x) + [m -D(G(z))]^{+}
$$

$$
L_{G}(z) = D(G(z))
$$

[ EBGAN paper review ](https://dogfoottech.tistory.com/183)
### 2.6.6 Wasserstein Generative Adversarial Networks (WGAN)
### 2.6.7 Boundary Equilibrium Generative Adversarial Networks (BEGAN)
### 2.6.8 Progressive-Growing Generative Adversarial Networks (PGGAN)
### 2.6.9 Big Generative Adversarial Networks (BigGAN)
### 2.6.10 Style-Based Generator Architecture for Generative Adversarial Networks(StyleGAN)




